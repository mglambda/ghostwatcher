# types.py
# types for the ghostwatcher project

from typing import *
import re
import json
from pydantic import BaseModel, Field
from enum import StrEnum
from pathlib import Path
from loguru import logger

from ghostbox import Ghostbox


class ExtractionStrategy(StrEnum):
    keyframes = "keyframes"
    interval = "interval"


class ImageExtractorConfig(BaseModel):
    """Config object containing parameters for various extraction functions.
    Not all of the options may be used by all of the functions"""

    use_keyframes: bool = Field(
        default=True, description="Use keyframes or iframes if available in the video."
    )

    min_interval: Optional[float] = Field(
        default=None, description="Minimum interval in seconds between images."
    )

    max_interval: Optional[float] = Field(
        default=None, description="Maximum interval in seconds between images."
    )

    # more options to come in the future


class ImageExtractor(Protocol):
    """Interface for video image extractor functions."""

    def process(
        self,
        video_filepath: str,
        output_path: Path,
        config: ImageExtractorConfig,
    ) -> None:
        pass


class FrameImage(BaseModel):
    """Small wrapper to represent a single video frame, with possible metadata and descriptions."""

    filepath: str = Field(description="The filepath to this frame's image file.")

    seek_pos: float = Field(
        default=-1.0,
        description="The time position in seconds at which this frame occurs in the video. Negative values indicate that the position could not be determined.",
    )

    description: Optional[str] = Field(
        default=None,
        description="An image description generated by a multimodal AI. May built upon descriptions of preceding images.",
    )


class FrameCollection(BaseModel):
    """An ordered collection of image frames, with possible descriptions and metadata."""

    video_filepath: str = Field(
        description="Filepath to the video that the frames belong to. Mostly for logging and documentation purposes."
    )

    frames: List[FrameImage] = Field(
        default_factory=list,
        description="The frames, in chronological order, that were extracted from the video.",
    )

    @staticmethod
    def from_directory(output_path: Path, video_filepath: str) -> "FrameCollection":
        """Create a new framecollection with empty metadata by loading all images from a directory in alphabetical order."""

        image_files = []
        for f in output_path.iterdir():
            if f.is_file() and f.suffix.lower() in [".png", ".jpg", ".jpeg"]:
                image_files.append(f)

        # Sort files alphabetically to maintain chronological order
        image_files.sort()

        frames = []
        for img_file in image_files:
            seek_pos = -1.0
            # Try to extract timestamp from filename (e.g., frame-0001-ts-12.345.png)
            ts_match = re.search(r"-ts-([\d\.]+)", img_file.stem)
            if ts_match:
                try:
                    seek_pos = float(ts_match.group(1))
                except ValueError:
                    pass

            frames.append(FrameImage(filepath=str(img_file), seek_pos=seek_pos))

        return FrameCollection(video_filepath=video_filepath, frames=frames)


    def merge(self, other: 'FrameCollection') -> None:
        """Merges data members from OTHER framecollection into this one, if the update would be non-destructive.
        For example, this will replace frame descriptions with the descriptions from other, but only if the frame matches and this instance's description member is None.
        If the two collections don't match, this method does nothing."""
        # FIXME: this is currently unused and might be removed
        # sanity check
        if self.video_filepath != other.video_filepath:
            logger.debug(f"Skipping merge due to mismatched filepaths {self.video_filepath} and {other.video_filepath}.")
            return

        if len(self.frames) != len(other.frames):
            logger.debug(f"Skipping merge of frame collections due to mismatched number of frames.")
            return

        # invariant: the length is equal
        for i in range(len(self.frames)):
            self_frame = self.frames[i]
            other_frame = other.frames[i]
            if self_frame.filepath != other_frame.filepath:
                logger.debug(f"Continue on merge of frames due to mismatched filapths {self_frame.filepath} and {other_frame.filepath}.")
                continue

            # update only if we are null
            if self_frame.description is None:
                self_frame.description = other_frame.description

        
    def save(self, filepath: Path) -> None:
        """Save the frame collection to a JSON file."""
        filepath.write_text(self.model_dump_json(indent=2))

    @staticmethod
    def load(filepath: Path) -> "FrameCollection":
        """Load a frame collection from a JSON file."""
        return FrameCollection.model_validate_json(filepath.read_text())

class LLMConfig(BaseModel):
    """Configuration parameters for the image description generation that are used with the LLM backend."""

    batch_size: int = Field(
        default=3,
        description="How many images to describe in one batch. A higher batch size gives better results because the LLM will have more images in context simultaneously, but also requires substantially more memory and processing time.",
    )

    batch_description_prompt_part: str = Field(
        default="Here are several still frames from a video. All but the last one have been previously described. Focus on the last image, do not repeat describing the first few images, but do include contextual knowledge of them   in your description, and describe any changes that have taken place in the newest image compared to the previous ones.",
        description="Text snippet included in the image description prompt if the batch size is greater than 1.",
    )

    description_prompt: str = Field(
        default="Describe the image.",
        description="Prompt used for basic image descriptions.",
    )

    caption_frame_context: int = Field(
        default = 16,
        description = "How many frame descriptions to keep in context when generating video captions. Half of the context frames will be sourced from frames before the one that is being captioned, the other half from frame that come after. Currently unused."
    )

    caption_batch_size: int = Field(
        default = 16,
        description = "How many frames to cluster together when prompting the LLM to generate captions. Note that all the image descriptions will be included, so a larger batch size here will require more context and video ram. A smaller batch size can lead to the AI repeating itself in the captions, and being unable to find the actually relevant information."
    )
    
    caption_prompt: str = Field(
        default = "Above are several descriptions for image frames at certain time positions in a video. Please generate descriptive captions for specific time positions based on the above descriptions. The captions should be shorter than the full length descriptions above, as they will be spoken out using a TTS program and laid over the video. Try to find relevant changes and breakpoints to put captions, and generate captions that go deeper into description if nothing new occurs. Focus on major changes and big picture impressions, while occasionally dropping specific details.\nImportant: Do not mention the time in the actual caption content (e.g. do not generate 'At 10.0 seconds...'), and be sure to leave an adequate amount of time between the captions, so that their spoken-out versions do not overlap (the seek_pos is the time in the video the speech output will start for that caption).\nNote: The seek_pos time position is always in seconds.",
        description = "The prompt given to the LLM to generate captions."
    )

class Caption(BaseModel):
    """A single caption line for a video. A caption line describes the state of affairs displayed in the video at a given moment, in the context of the entire video."""

    content: str = Field(
        description = "The text content of the caption. It should be a description of what is shown in the video, while taking previous video content into account. The text should be reasonably short, in a way that may be displayed or spoken out while the video is playing."
    )
    
    seek_pos: float = Field(
        description = "The time position, in seconds, at which this caption applies."
    )
    
class VideoCaptions(BaseModel):
    """Container for captions intended for a video file."""

    video_filepath: str = Field(
        description = "path of the video file these captions belong to."
    )

    captions: List[Caption] = Field(
        default_factory = list,
        description = "List of individual caption lines."
    )

    def save(self, filepath: Path) -> None:
        """Save the video captions to a JSON file."""
        filepath.write_text(self.model_dump_json(indent=2))

    @staticmethod
    def load(filepath: Path) -> "VideoCaptions":
        """Load video captions from a JSON file."""
        return VideoCaptions.model_validate_json(filepath.read_text())

class Program(BaseModel, arbitrary_types_allowed=True):
    """Holds context relevant for program execution."""

    output_dir: Path = Field(
        description="Directory where the final output will be stored."
    )

    work_dir: Path = Field(
        description="Directory where intermediate results and other temporary files will be stored. The directory may be temporary."
    )

    box: Ghostbox = Field(description="Ghostbox instance.")

    def get_extraction_output_dir(self) -> Path:
        """Returns the path to the directory that should contain extracted frames. Ensures the directory exists."""
        extraction_output_dir = self.work_dir / "extracted_frames"
        extraction_output_dir.mkdir(parents=True, exist_ok=True)
        return extraction_output_dir


    def get_frame_collection_path(self) -> Path:
        """Returns the path to the file that contains the program's frame collection.
        This can be used to store intermediate results and to restore previous runs of the program."""
        return self.work_dir / "frame_collection.json"

    def get_captions_path(self) -> Path:
        """Returns the path to the file that stores video captions."""
        return self.work_dir / "video_captions.json"        
